# Docker Compose with Nginx Reverse Proxy
# This configuration adds an Nginx reverse proxy in front of all services
# Features:
# - SSL/TLS termination
# - Load balancing support
# - WebSocket proxy
# - Rate limiting and security headers

services:
  # Nginx Reverse Proxy
  nginx:
    image: nginx:1.25-alpine
    container_name: workflow-nginx
    restart: unless-stopped
    ports:
      - '${HTTP_PORT:-80}:80'
      - '${HTTPS_PORT:-443}:443'
    volumes:
      # Nginx configuration
      - ./nginx-reverse-proxy.conf:/etc/nginx/conf.d/default.conf:ro
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      # SSL certificates (mount your certificates here)
      - ${SSL_CERT_PATH:-./ssl}:/etc/nginx/ssl:ro
      # Let's Encrypt challenge directory
      - ${CERTBOT_PATH:-./certbot/www}:/var/www/certbot:ro
      # Cache directory
      - nginx_cache:/var/cache/nginx
      # Logs
      - nginx_logs:/var/log/nginx
    environment:
      - DOMAIN_NAME=${DOMAIN_NAME:-localhost}
    networks:
      - workflow-network
    depends_on:
      - frontend
      - bff
      - ai-service
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:80/health']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Certbot for Let's Encrypt SSL certificates (optional)
  certbot:
    image: certbot/certbot:latest
    container_name: workflow-certbot
    volumes:
      - ${SSL_CERT_PATH:-./ssl}:/etc/letsencrypt
      - ${CERTBOT_PATH:-./certbot/www}:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    networks:
      - workflow-network
    profiles:
      - ssl

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: workflow-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-workflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-workflow_password}
      POSTGRES_DB: ${POSTGRES_DB:-workflow_db}
      POSTGRES_INITDB_ARGS: '-E UTF8 --locale=en_US.UTF-8'
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - workflow-network
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-workflow}']
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: workflow-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - workflow-network
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: workflow-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - workflow-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:11434/api/tags']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  # AI Service (Python/FastAPI)
  ai-service:
    build:
      context: ..
      dockerfile: docker/ai-service.Dockerfile
    container_name: workflow-ai-service
    restart: unless-stopped
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - WORKERS=${AI_SERVICE_WORKERS:-4}
    networks:
      - workflow-network
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      # Uncomment for horizontal scaling
      # replicas: 3

  # BFF Service (NestJS)
  bff:
    build:
      context: ..
      dockerfile: docker/bff.Dockerfile
    container_name: workflow-bff
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER:-workflow}:${POSTGRES_PASSWORD:-workflow_password}@postgres:5432/${POSTGRES_DB:-workflow_db}
      - REDIS_URL=redis://redis:6379
      - AI_SERVICE_URL=http://ai-service:8000
      - JWT_SECRET=${JWT_SECRET:-change-me-in-production}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN:-7d}
      - PORT=3001
      - CORS_ORIGIN=${CORS_ORIGIN:-https://${DOMAIN_NAME:-localhost}}
    networks:
      - workflow-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ai-service:
        condition: service_healthy
    healthcheck:
      test:
        [
          'CMD',
          'node',
          '-e',
          "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})",
        ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    command: sh -c "npx prisma migrate deploy && node dist/main.js"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      # Uncomment for horizontal scaling
      # replicas: 3

  # Frontend (Vue3/Nginx)
  frontend:
    build:
      context: ..
      dockerfile: docker/frontend.Dockerfile
    container_name: workflow-frontend
    restart: unless-stopped
    networks:
      - workflow-network
    depends_on:
      - bff
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:80/health']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
      # Uncomment for horizontal scaling
      # replicas: 2

networks:
  workflow-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local
